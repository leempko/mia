["Model-based Segmentation: Part II Koen Van Leemput Fall 2024 Medical Image Analysis This work is licensed under CC BY 4.0 ","MRI image The problem to be solved Label image : number of classes voxels : intensity in voxel ","One solution: generative modeling – Formulate a statistical model of image formation “labeling model” “imaging model” MRI image Label image – The model depends on some parameters ","Segmentation = inverse problem MRI image Label image ","MRI image Segmentation = inverse problem Label image Bayesian inference – Play with the mathematical rules of probability ","Gaussian mixture model – Assign a label to each voxel independently – Probability of assigning label is “labeling model” “imaging model” MRI image Label image ","Gaussian mixture model – Draw the intensity in each voxel with label from a Gaussian distribution with mean and variance “labeling model” “imaging model” MRI image Label image ","Gaussian mixture model labels ","Gaussian mixture model – Apply Bayes’ rule: ","Gaussian mixture model white matter gray matter CSF ","How to obtain ? Today's lecture ","Today's lecture How to obtain ? ","How to obtain model parameters? – Click manually on some representative points for each label – “Train once, apply forever” – Doesn't work well in MRI: ✔ different imaging protocols ✔ different scanner platforms (make, version) ✔ software/hardware upgrades ✔ …. ","How to obtain model parameters? – Click manually on some representative points for each label – “Train once, apply forever” – Doesn't work well in MRI: ✔ different imaging protocols ✔ different scanner platforms (make, version) ✔ software/hardware upgrades ✔ …. Let’s estimate the model parameters automatically from each individual scan ","Parameter optimization Estimate the maximum likelihood parameters: ","Task: 1. Is this valid? Could I use sine() instead of log()? 2. Benefit? Hint: compute (0.01)^1000 in Matlab/Python Parameter optimization Estimate the maximum likelihood parameters: ","Parameter optimization Expectation Maximization (EM) algorithm: – Repeatedly maximize a lower bound to the objective function ","Parameter optimization Expectation Maximization (EM) algorithm: – Repeatedly maximize a lower bound to the objective function (current estimate) ","Parameter optimization Expectation Maximization (EM) algorithm: (current estimate) – Repeatedly maximize a lower bound to the objective function ","Parameter optimization Expectation Maximization (EM) algorithm: – Repeatedly maximize a lower bound to the objective function (current estimate) ","Parameter optimization Expectation Maximization (EM) algorithm: – Repeatedly maximize a lower bound to the objective function (current estimate) ","Parameter optimization Expectation Maximization (EM) algorithm: – Repeatedly maximize a lower bound to the objective function (current estimate) ","Parameter optimization Expectation Maximization (EM) algorithm: – Repeatedly maximize a lower bound to the objective function (current estimate) ","Parameter optimization Expectation Maximization (EM) algorithm: – Repeatedly maximize a lower bound to the objective function (current estimate) ","Parameter optimization Expectation Maximization (EM) algorithm: – Repeatedly maximize a lower bound to the objective function – Guaranteed to never move in a wrong direction! (current estimate) ","Constructing the lower bound Extends easily to more than two variables (Jensen’s inequality): ","Constructing the lower bound current estimate ","Constructing the lower bound current estimate ","Constructing the lower bound current estimate Question : are random weights enough? ","Constructing the lower bound current estimate ","Constructing the lower bound current estimate ","Constructing the lower bound current estimate No! ","Constructing the lower bound current estimate The lower bound touches the objective function at the current parameter estimate if ","current estimate The lower bound touches the objective function at the current parameter estimate if Constructing the lower bound ","Maximizing the lower bound Lower bound: new estimate ? ","Task: 1. What is ? 2. What is ? 3. What is ? Maximizing the lower bound Lower bound: new estimate ? ","Maximizing the lower bound Lower bound: new estimate ? ","Parameter optimizer summarized MRI data classification Classify the image voxels according to the current parameter estimate (“E-step”) ","Parameter optimizer summarized Update the parameter estimate based on the current classification (“M-step”) ","Parameter optimizer summarized – Repeatedly apply closed- form parameter updates – Each iteration improves the log likelihood ","Example initialization initialization ","Example after one iteration ","Example after 10 iterations ","Example after 30 iterations ","Example white matter gray matter CSF ","MRI “bias field” artifact – Imaging artifact in MRI – Smooth intensity variations across the image area MRI data after intensity windowing… ","MRI “bias field” artifact – Depends on the object being scanned – More pronounced on high-field scanners 1.5 Tesla scanner 3 Tesla scanner 7 Tesla scanner ","MRI “bias field” artifact Causes segmentation errors with our segmentation procedure so far… ","MRI “bias field” artifact Causes segmentation errors with our segmentation procedure so far… ","Generative model “labeling model” “imaging model” MRI image Label image “labeling model” “imaging model” MRI image Label image ","Improved imaging model “labeling model” “imaging model” MRI image Label image “labeling model” “imaging model” MRI image Label image ","Improved imaging model “labeling model” “imaging model” MRI image Label image old model “labeling model” “imaging model” MRI image Label image ","Improved imaging model + old model parametric bias field model “labeling model” “imaging model” MRI image Label image ","Bias field model Linear combination of smooth basis functions : parameters of the bias field model : value of the mth basis function in voxel ","Bias field model = ","Parameter optimization – Bias field parameters are part of the model parameters – Parameter optimization with a Generalized Expectation Maximization (GEM) algorithm – Repeatedly improve a lower bound to the log likelihood function – Still guaranteed to never move in a wrong direction! (current estimate) ","Constructing the lower bound current estimate – Same derivations as before – The lower bound touches the objective function at current parameter estimate if ","Improving the lower bound ","Improving the lower bound ","Improving the lower bound (cont.) ✔ cf. linear regression ✔ smoothing operation ","Improving the lower bound (cont.) ✔ cf. linear regression ✔ smoothing operation ","E-step MRI data classification bias field ","M-step part 1: distribution estimation MRI data classification bias field ","M-step part 2: bias field estimation predicted classification ","M-step part 2: bias field estimation predicted classification weights ","M-step part 2: bias field estimation = - predicted weights MRI data residue bias field weighted smoothing ","Parameter optimizer summarized – Repeatedly apply closed- form parameter updates – Each iteration improves the likelihood ","Example MRI data Estimated bias field Bias-corrected MRI data ","Example MRI data White matter without bias field model White matter with bias field model Estimated bias field ","Example MRI data White matter without bias field model White matter with bias field model Estimated bias field "]