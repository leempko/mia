["Neural Networks Koen Van Leemput Medical Image Analysis This work is licensed under CC BY 4.0 ","Focus: automatic segmentation images segmentation ","Remember the Gaussian mixture model? Posterior using Bayes’ rule: ","Posterior using Bayes’ rule: This lecture: can we get a “classifier” directly without a model ? Remember the Gaussian mixture model? ","Posterior using Bayes’ rule: new notation/terminology: - “training samples” - “t=1” if l=1 - “t=0” if l=2 This lecture: can we get a “classifier” directly without a model ? Remember the Gaussian mixture model? ","Remember linear regression? – Let denote an input vector in a -dimensional space – Given measurements at inputs , what is at a new input ? tunable weights nonlinear basis functions ","Logistic regression – Logistic function as a “squashing” function ","Logistic regression – where – Of course: regression for binary outcomes: ","Voxel-based classifier – Training data with (i.e., ) and – Estimate parameters by maximizing the likelihood ","Voxel-based classifier – Training data with (i.e., ) and – Estimate parameters by maximizing the likelihood ","Voxel-based classifier – Training data with (i.e., ) and – Estimate parameters by maximizing the likelihood ","Voxel-based classifier – Training data with (i.e., ) and – Estimate parameters by maximizing the likelihood ","Voxel-based classifier – Once trained keep the classifier: – Simply apply it to new data: ","Optimization algorithm for training – Maximizing the likelihood function is equivalent to minimizing – Gradient descent: with gradient – Stochastic gradient descent: use only randomly sampled training points, and approximate: step size (user-specified) ","More fun: patch-based classifier – Classify 3x3 image “patches”: intensity of the pixel to be classified + intensities of 8 neighboring pixels – is now a 9-dimensional vector ( ), but otherwise everything is the same: – But how to choose basis functions in a 9-dimensional space? ","Basis functions in high dimensions? – Idea: remember the “separable basis functions” trick? “making” sixteen 2D basis functions out of two sets of four 1D basis functions Question : does this work in 9D? ","Basis functions in high dimensions? – Idea: remember the “separable basis functions” trick? “making” sixteen 2D basis functions out of two sets of four 1D basis functions Question : does this work in 9D? No! 4^9 = 262144 basis functions! ","Adaptive basis functions – Introduce extra parameters that alter the form of a limited set of basis functions – Prototypical example: – All parameters ( and ) are optimized together during training (stochastic gradient descent) extra parameters ","Adaptive basis functions (D=1) ","Adaptive basis functions (D=1) ","Adaptive basis functions (D=1) ","Adaptive basis functions (D=2) ","Feed-forward neural network So the model is: with basis functions parameters ","Feed-forward neural network Graphical representation of our 3x3 patch-based classifier (D=9 and M=4): – – Can insert more than one “hidden” layer (“deep learning”) flow of information “hidden units” ","XX Applying the trained classifier on new data: ","XX filter filter filter Applying the trained classifier on new data: ","XX filter filter filter Applying the trained classifier on new data: Filtering operations can be implemented using convolutions => “convolutional neural network” ","Neural networks = ultimate solution? No model, only training data: - No domain expertise needed - Very easy to train and deploy - Super fast (GPUs) - Training data often very hard to get in medical imaging! - Scanning hardware/software/protocol changes routinely! "]