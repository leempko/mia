<!DOCTYPE html>
<html>
<head>
<meta http-equiv="X-UA-Compatible" content="IE=Edge" />
<meta charset="utf-8" />
</head>

<body style="margin: 0;">

<div id="p55" style="overflow: hidden; position: relative; background-color: white; width: 935px; height: 1210px;">

<!-- Begin shared CSS values -->
<style class="shared-css" type="text/css" >
.t {
	transform-origin: bottom left;
	z-index: 2;
	position: absolute;
	white-space: pre;
	overflow: visible;
	line-height: 1.5;
}
.text-container {
	white-space: pre;
}
@supports (-webkit-touch-callout: none) {
	.text-container {
		white-space: normal;
	}
}
</style>
<!-- End shared CSS values -->


<!-- Begin inline CSS -->
<style type="text/css" >

#t1_55{left:163px;bottom:876px;letter-spacing:-0.24px;word-spacing:3.95px;}
#t2_55{left:163px;bottom:796px;letter-spacing:-0.27px;word-spacing:5.12px;}
#t3_55{left:163px;bottom:726px;letter-spacing:0.08px;word-spacing:2.96px;}
#t4_55{left:163px;bottom:708px;letter-spacing:0.1px;word-spacing:2.48px;}
#t5_55{left:252px;bottom:708px;letter-spacing:-0.05px;}
#t6_55{left:303px;bottom:708px;letter-spacing:0.09px;word-spacing:2.5px;}
#t7_55{left:163px;bottom:690px;letter-spacing:0.07px;word-spacing:0.58px;}
#t8_55{left:163px;bottom:671px;letter-spacing:0.07px;word-spacing:2.46px;}
#t9_55{left:163px;bottom:653px;letter-spacing:0.1px;word-spacing:0.41px;}
#ta_55{left:163px;bottom:635px;letter-spacing:0.05px;word-spacing:1.36px;}
#tb_55{left:186px;bottom:616px;letter-spacing:0.08px;word-spacing:2.48px;}
#tc_55{left:163px;bottom:597px;letter-spacing:0.09px;word-spacing:3.74px;}
#td_55{left:671px;bottom:597px;letter-spacing:0.13px;}
#te_55{left:163px;bottom:579px;letter-spacing:0.12px;word-spacing:3.08px;}
#tf_55{left:480px;bottom:579px;}
#tg_55{left:488px;bottom:579px;letter-spacing:0.1px;word-spacing:3.23px;}
#th_55{left:163px;bottom:561px;letter-spacing:0.08px;word-spacing:2.95px;}
#ti_55{left:361px;bottom:561px;letter-spacing:0.1px;}
#tj_55{left:463px;bottom:561px;letter-spacing:0.09px;}
#tk_55{left:532px;bottom:561px;letter-spacing:0.04px;word-spacing:3.03px;}
#tl_55{left:163px;bottom:543px;letter-spacing:0.1px;word-spacing:1.5px;}
#tm_55{left:163px;bottom:524px;letter-spacing:0.02px;}
#tn_55{left:216px;bottom:524px;letter-spacing:0.08px;word-spacing:2.6px;}
#to_55{left:163px;bottom:506px;letter-spacing:0.1px;word-spacing:1.26px;}
#tp_55{left:163px;bottom:488px;letter-spacing:0.07px;word-spacing:1.32px;}
#tq_55{left:186px;bottom:469px;letter-spacing:0.1px;word-spacing:3.05px;}
#tr_55{left:163px;bottom:450px;letter-spacing:0.11px;word-spacing:2.01px;}
#ts_55{left:163px;bottom:432px;}
#tt_55{left:236px;bottom:432px;letter-spacing:0.05px;word-spacing:2.42px;}
#tu_55{left:163px;bottom:414px;letter-spacing:0.1px;word-spacing:2.96px;}
#tv_55{left:163px;bottom:395px;letter-spacing:0.13px;word-spacing:3.37px;}
#tw_55{left:553px;bottom:395px;letter-spacing:0.11px;word-spacing:3.41px;}
#tx_55{left:163px;bottom:377px;letter-spacing:0.07px;word-spacing:0.95px;}
#ty_55{left:163px;bottom:359px;letter-spacing:0.1px;word-spacing:2.37px;}
#tz_55{left:163px;bottom:341px;letter-spacing:0.1px;word-spacing:2.34px;}
#t10_55{left:163px;bottom:322px;letter-spacing:0.08px;word-spacing:1.63px;}
#t11_55{left:163px;bottom:304px;letter-spacing:0.08px;word-spacing:3.59px;}
#t12_55{left:163px;bottom:286px;letter-spacing:0.05px;word-spacing:1.36px;}
#t13_55{left:163px;bottom:227px;letter-spacing:-0.04px;}
#t14_55{left:219px;bottom:227px;letter-spacing:-0.04px;word-spacing:2.74px;}
#t15_55{left:163px;bottom:195px;letter-spacing:0.11px;word-spacing:1.8px;}
#t16_55{left:243px;bottom:195px;}
#t17_55{left:256px;bottom:195px;letter-spacing:0.09px;word-spacing:1.82px;}
#t18_55{left:163px;bottom:177px;letter-spacing:-0.01px;word-spacing:0.51px;}
#t19_55{left:351px;bottom:177px;}
#t1a_55{left:369px;bottom:177px;letter-spacing:0.07px;word-spacing:0.35px;}
#t1b_55{left:418px;bottom:138px;letter-spacing:0.11px;}

.s0_55{font-size:32px;font-family:CMBX12_-i;color:#000;}
.s1_55{font-size:38px;font-family:CMBX12_-i;color:#000;}
.s2_55{font-size:15px;font-family:CMR10_109;color:#000;}
.s3_55{font-size:15px;font-family:CMTI10_10z;color:#000;}
.s4_55{font-size:15px;font-family:CMR10_109;color:#00F;}
.s5_55{font-size:22px;font-family:CMBX12_-i;color:#000;}
.s6_55{font-size:15px;font-family:CMMI10_-u;color:#000;}
</style>
<!-- End inline CSS -->

<!-- Begin embedded font definitions -->
<style id="fonts55" type="text/css" >

@font-face {
	font-family: CMBX12_-i;
	src: url("fonts/CMBX12_-i.woff") format("woff");
}

@font-face {
	font-family: CMMI10_-u;
	src: url("fonts/CMMI10_-u.woff") format("woff");
}

@font-face {
	font-family: CMR10_109;
	src: url("fonts/CMR10_109.woff") format("woff");
}

@font-face {
	font-family: CMTI10_10z;
	src: url("fonts/CMTI10_10z.woff") format("woff");
}

</style>
<!-- End embedded font definitions -->

<!-- Begin page background -->
<div id="pg55Overlay" style="width:100%; height:100%; position:absolute; z-index:1; background-color:rgba(0,0,0,0); -webkit-user-select: none;"></div>
<div id="pg55" style="-webkit-user-select: none;"><svg id="pdf55" width="935" height="1210" viewBox="0 0 935 1210" style="width:935px; height:1210px; -moz-transform:scale(1); z-index: 0; isolation: isolate;" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
<defs>
</defs>
</svg></div>
<!-- End page background -->


<!-- Begin text definitions (Positioned/styled in CSS) -->
<div class="text-container"><span id="t1_55" class="t s0_55">Chapter 4 </span>
<span id="t2_55" class="t s1_55">Neural Networks </span>
<span id="t3_55" class="t s2_55">The methods for registration and segmentation that we have seen so far are </span>
<span id="t4_55" class="t s2_55">all based on </span><span id="t5_55" class="t s3_55">models </span><span id="t6_55" class="t s2_55">that somehow encode prior knowledge of the problem at </span>
<span id="t7_55" class="t s2_55">hand. For instance, mutual information-based registration exploits the fact that </span>
<span id="t8_55" class="t s2_55">one image is predictive of another image only when the two are well aligned; </span>
<span id="t9_55" class="t s2_55">while the Gaussian mixture model for segmentation encodes the knowledge that </span>
<span id="ta_55" class="t s2_55">voxels with the same label typically have similar intensities. </span>
<span id="tb_55" class="t s2_55" data-mappings='[[15,"ff"]]'>A completely diﬀerent approach to solving a problem is not to try to un- </span>
<span id="tc_55" class="t s2_55">derstand it, but rather to simply emulate successful example solutions. </span><span id="td_55" class="t s2_55">As </span>
<span id="te_55" class="t s2_55">opposed to the generative models of Chapter </span><span id="tf_55" class="t s4_55">3</span><span id="tg_55" class="t s2_55">, this approach to model-free </span>
<span id="th_55" class="t s2_55">“machine learning” is called </span><span id="ti_55" class="t s3_55">discriminative </span><span id="tj_55" class="t s2_55">learning. </span><span id="tk_55" class="t s2_55">In this chapter we will </span>
<span id="tl_55" class="t s2_55" data-mappings='[[14,"fi"],[62,"fi"]]'>review a speciﬁc class of discriminative methods based on artiﬁcial neural net- </span>
<span id="tm_55" class="t s2_55">works. </span><span id="tn_55" class="t s2_55">Although such networks can also be used for other purposes, such as </span>
<span id="to_55" class="t s2_55">image registration and computer aided diagnosis, they are especially successful </span>
<span id="tp_55" class="t s2_55">in the area of image segmentation, which we will focus on in this chapter. </span>
<span id="tq_55" class="t s2_55" data-mappings='[[55,"ffi"]]'>In general, it should be noted that sidestepping the diﬃculty of building </span>
<span id="tr_55" class="t s2_55">models is both the main strength and the most important weakness of neural </span>
<span id="ts_55" class="t s2_55">networks. </span><span id="tt_55" class="t s2_55" data-mappings='[[13,"ffi"]]'>As long as suﬃcient example solutions are available, they are very </span>
<span id="tu_55" class="t s2_55" data-mappings='[[49,"fi"]]'>easy to deploy without requiring any domain-speciﬁc knowledge, and can be </span>
<span id="tv_55" class="t s2_55">orders of magnitude faster than model-based methods. </span><span id="tw_55" class="t s2_55">On the other hand, </span>
<span id="tx_55" class="t s2_55">however, example solutions are often in short supply in medical image analysis, </span>
<span id="ty_55" class="t s2_55">as manually annotating a large set of images can be excruciatingly time con- </span>
<span id="tz_55" class="t s2_55">suming. Especially in versatile imaging modalities such as MRI, this problem </span>
<span id="t10_55" class="t s2_55" data-mappings='[[24,"ff"]]'>is exacerbated by the diﬀerences in scanning hardware, software and protocols </span>
<span id="t11_55" class="t s2_55">that exist even within the same hospital, which can make carefully curated </span>
<span id="t12_55" class="t s2_55">example solutions useless overnight. </span>
<span id="t13_55" class="t s5_55">4.1 </span><span id="t14_55" class="t s5_55">Logistic regression </span>
<span id="t15_55" class="t s2_55">In Chapter </span><span id="t16_55" class="t s4_55">3 </span><span id="t17_55" class="t s2_55">we saw how the Gaussian mixture model can be used to classify </span>
<span id="t18_55" class="t s2_55">each image voxel into one of </span><span id="t19_55" class="t s6_55">K </span><span id="t1a_55" class="t s2_55" data-mappings='[[2,"ff"]]'>diﬀerent classes (tissue types) based on its inten- </span>
<span id="t1b_55" class="t s2_55">51 </span></div>
<!-- End text definitions -->


</div>
</body>
</html>
